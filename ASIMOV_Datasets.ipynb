{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASIMOV datasets\n",
        "https://asimov-benchmark.github.io/"
      ],
      "metadata": {
        "id": "UtRnuvdjnqMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Code"
      ],
      "metadata": {
        "id": "8qpjnsRInaLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install mediapy\n",
        "!pip install tfds-nightly   # to get most up-to-date registered datasets\n",
        "!pip install apache_beam"
      ],
      "metadata": {
        "id": "kfRN3Q_lS7M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "import tensorflow as tf\n",
        "\n",
        "print_fn = lambda x: display(Markdown(x))\n",
        "\n",
        "try:\n",
        "  import mediapy as mpy\n",
        "except ModuleNotFoundError:\n",
        "  print('Not displaying images.')\n",
        "  mpy = None\n",
        "\n",
        "\n",
        "class Sample():\n",
        "  def __init__(self, example, display_one_instruction=True):\n",
        "    self.example = example\n",
        "    self.display_one_instruction = display_one_instruction\n",
        "\n",
        "  def display(self):\n",
        "    newline = '<br>'\n",
        "    for k, v in self.example.items():\n",
        "      if 'image' in k:\n",
        "        print_fn(f'**{k}**:')\n",
        "        print_fn(f'image of size {v.numpy().shape}')\n",
        "        if mpy:\n",
        "          mpy.show_image(v.numpy())\n",
        "      elif k == 'instructions':\n",
        "        for i in range(len(v['instruction'])):\n",
        "          sample_dict = {}\n",
        "          for ik, iv in v.items():\n",
        "            sample_dict[ik] = iv[i]\n",
        "          sample = Sample(sample_dict)\n",
        "          print_fn('---')\n",
        "          print_fn(f'## Sample Entry {i+1}{newline}')\n",
        "          sample.display()\n",
        "          if self.display_one_instruction:\n",
        "            break\n",
        "      else:\n",
        "        if isinstance(v, tf.Tensor) and v.dtype == tf.string:\n",
        "          v = v.numpy()\n",
        "          if isinstance(v, bytes):\n",
        "            v = v.decode('utf-8')\n",
        "        print_fn(f'**{k}**: {v}{newline}{newline}')\n",
        "\n",
        "def get_single_example(dataset_name: str):\n",
        "  builder = tfds.builder_from_directory(\n",
        "      f'gs://gresearch/robotics/{dataset_name}/0.1.0/'\n",
        "  )\n",
        "  any_split = list(builder.info.splits.keys())[0]\n",
        "  ds = builder.as_dataset(split=any_split)\n",
        "  it = iter(ds)\n",
        "  example = next(it)\n",
        "  return example"
      ],
      "metadata": {
        "id": "6UCJ7QmWIORW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the datasets from the GCS bucket\n",
        "\n",
        "A sanity check featuring how to load each dataset from GCS bucket."
      ],
      "metadata": {
        "id": "Iu3paI2udOyn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqr1iUQF9EE-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "DATASETS = [\n",
        "    'asimov_injury_val',  # Situations generated from real hospital injury reports (validation set).\n",
        "    'asimov_dilemmas_auto_val',  # Binary dilemma questions generated from counterfactual situations used to auto-amend generated constitutions (validation set).\n",
        "    'asimov_dilemmas_scifi_train',  # Multiple-choice ethical questions (with desirable and undesirable answers) based on situations inspired from Science Fiction literature (training set).\n",
        "    'asimov_dilemmas_scifi_val',  # Multiple-choice ethical questions (with desirable and undesirable answers) based on situations inspired from Science Fiction literature (validation set).\n",
        "    'asimov_multimodal_auto_val',  # (Image, context, instruction) triplets generated from real images (from RoboVQA dataset) which are modified to contain undesirable elements, generated instructions can be desirable or undesirable (validation set).\n",
        "    'asimov_multimodal_manual_val',  # (Image, context, instruction) triplets manually taken and written by humans while ensuring that the instruction desirability can only be determined by looking at the image (validation set).\n",
        "]\n",
        "\n",
        "i = 0\n",
        "for ds_name in DATASETS:\n",
        "  builder = tfds.builder_from_directory(\n",
        "      f'gs://gresearch/robotics/{ds_name}/0.1.0/'\n",
        "  )\n",
        "  for split in builder.info.splits.keys():\n",
        "    ds = builder.as_dataset(split=split)\n",
        "    it = iter(ds)\n",
        "    example = next(it)\n",
        "    assert example is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the datasets from the TFDS Catalog\n",
        "\n",
        "A sanity check featuring how to load each dataset registered in TFDS Catalog. This will download and cache the datasets to the local disk for fast access."
      ],
      "metadata": {
        "id": "GqEqEG0MdIm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "DOWNLOAD_DIR = '/tmp/tensorflow_datasets'\n",
        "\n",
        "for ds_name in DATASETS:\n",
        "  print(f'Loading the dataset {ds_name}')\n",
        "  ds = tfds.load(ds_name, data_dir=DOWNLOAD_DIR)\n",
        "  for split in builder.info.splits.keys():\n",
        "    ds = builder.as_dataset(split=split)\n",
        "    it = iter(ds)\n",
        "    example = next(it)\n",
        "    assert example is not None"
      ],
      "metadata": {
        "id": "pl5gj2KSb0j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display `asimov_multimodal_auto_val` dataset"
      ],
      "metadata": {
        "id": "DNsfzlHXTl1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = get_single_example('asimov_multimodal_auto_val')\n",
        "sample = Sample(example)\n",
        "\n",
        "sample.display()"
      ],
      "metadata": {
        "id": "d2dypIv5ULFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display `asimov_dilemmas_auto_val` dataset"
      ],
      "metadata": {
        "id": "gduWUUjLWOSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = get_single_example('asimov_dilemmas_auto_val')\n",
        "sample = Sample(example)\n",
        "\n",
        "sample.display()"
      ],
      "metadata": {
        "id": "PiBnwxXlWaA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display `asimov_injury_val` dataset"
      ],
      "metadata": {
        "id": "Z_3j1scqWgcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = get_single_example('asimov_injury_val')\n",
        "sample = Sample(example)\n",
        "\n",
        "sample.display()"
      ],
      "metadata": {
        "id": "AA-F1KWoWb4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}